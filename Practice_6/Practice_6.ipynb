{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UOBJxTDNpmFv"
   },
   "source": [
    "<!--\n",
    "SPDX-FileCopyrightText: Copyright (c) 2024 Idiap Research Institute <contact@idiap.ch>\n",
    "SPDX-FileContributor: Alina Elena Baia <alina.baia.idiap.ch>\n",
    "SPDX-FileContributor: Darya Baranouskaya <darya.baranouskaya.idiap.ch>\n",
    "SPDX-FileContributor: Olena Hrynenko <olena.hrynenko.idiap.ch>\n",
    "-->\n",
    "\n",
    "# Practice exercises after Lecture 6\n",
    "This notebook contains the practice exercise with instructions and explanations.\n",
    "\n",
    "Work through the cells below in sequential order, executing each cell as you progress. Throughout the notebook, you will encounter instructions marked with the words **YOUR CODE HERE** followed by **raise NotImplementedError()**. You will have to substitute  *raise NotImplementedError()* with your own code.\n",
    "Follow the instructions and write the code to complete the tasks.\n",
    "\n",
    "Along the way, you will also find questions. Try to reflect on the questions before/after running the code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9_1Gk60RahpD"
   },
   "source": [
    "This notebook was developped at the [Idiap Research Institute](https://www.idiap.ch) by [Alina Elena Baia](mailto:alina.baia.idiap.ch>), [Darya Baranouskaya](mailto:darya.baranouskaya.idiap.ch), [Roberto Boghetti](mailto:roberto.boghetti@idiap.ch) and [Olena Hrynenko](mailto:olena.hrynenko.idiap.ch) (equal contribution).\n",
    "\n",
    "The code of this notebooks has been taked and adapted from official tutorials on [PyTorch geometric](https://pytorch-geometric.readthedocs.io/en/latest/get_started/colabs.html), which are available under MIT Copyright (c) 2023 PyG Team <team@pyg.org> licence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RoCTxQZbUiT1"
   },
   "source": [
    "The **aim** of the exercises is to:\n",
    "\n",
    "**6.1** Get familiar with [PyTorch geometric (PyG)](https://pytorch-geometric.readthedocs.io/en/latest/): how to load datasets, view information about the graphs\n",
    "\n",
    "**6.2** Understand [message passing framework](https://doi.org/10.48550/arXiv.1704.01212) in Graph Neural Networks (GNNs)\n",
    "\n",
    "**6.3** Implement Graph convolutional network (GCN) on the [PROTEINS](https://www.researchgate.net/profile/Cheng-Soon-Ong/publication/7782805_Protein_Function_Prediction_via_Graph_Kernels/links/09e41507e5184631f4000000/Protein-Function-Prediction-via-Graph-Kernels.pdf) dataset for a graphs classification task.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a5GUF7JdQITc"
   },
   "source": [
    "#####**6.1 Getting familiar with PyTorch geometric (PyG)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lsbmlc2C1HL-"
   },
   "source": [
    "We will be using PyTorch Geometric library for this exercise. \"PyG (PyTorch Geometric) is a library built upon PyTorch to easily write and train Graph Neural Networks (GNNs) for a wide range of applications related to structured data.\" [(reference)](https://pytorch-geometric.readthedocs.io/en/latest/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-03-27T08:34:04.364752Z",
     "iopub.status.busy": "2024-03-27T08:34:04.363975Z",
     "iopub.status.idle": "2024-03-27T08:34:06.486697Z",
     "shell.execute_reply": "2024-03-27T08:34:06.484556Z",
     "shell.execute_reply.started": "2024-03-27T08:34:04.364684Z"
    },
    "id": "Ph69Pr8Wp3xi",
    "outputId": "299a7713-2f39-499e-9d90-119eae395b73"
   },
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "\n",
    "# For efficient usage of the hardware resources when running on JupyterHub EPFL,\n",
    "# we will limit the number of threads. If you are running this code on your local\n",
    "# machine or on colab, the following code will not do anything.\n",
    "# piece of code were adopted from the notebooks developed at the Idiap Research Institute by Olivier Canévet.\n",
    "\n",
    "if re.search('^https://.*noto.*\\.epfl\\.ch$', os.environ.get(\"EXTERNAL_URL\", \"\")) != None:\n",
    "    num_threads_limit = 2\n",
    "else:\n",
    "    num_threads_limit = torch.get_num_threads()\n",
    "print(f\"Limiting the number of threads to {num_threads_limit}\")\n",
    "torch.set_num_threads(num_threads_limit)\n",
    "print(f\"PyTorch is using {torch.get_num_threads()} threads\")\n",
    "\n",
    "_ = torch.set_flush_denormal(True) # To avoid long training time on CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pjdz8gv78HDT"
   },
   "source": [
    "If you are using Noto to run this notebook, follow the instructions below to install install the packages necessary for the exercise:\n",
    "\n",
    "1) open a terminal and activate your virtual environment with the following command (instructions on how to create a virtual environment are available [here](https://moodle.epfl.ch/mod/forum/discuss.php?d=99699))\n",
    "\n",
    "```\n",
    "my_venvs_activate name_of_your_environment\n",
    "```\n",
    "2) get the torch version: after activating your virtual environment, open Python in interactive mode with the following command:\n",
    "```\n",
    "python\n",
    "```\n",
    "then, in Python interactive mode import torch and print the torch version using the following code:\n",
    "```\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "```\n",
    "You will get something like this: 2.0.1+cu117\n",
    "\n",
    "3) Install the packages using the command below. Make sure to replace ${TORCH} with your torch version.\n",
    "```\n",
    "pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
    "\n",
    "```\n",
    "If your torch version is 2.0.1+cu117 the installation commands will be:\n",
    "```\n",
    "pip install -q torch-scatter -f https://data.pyg.org/whl/torch-2.0.1+cu117.html\n",
    "pip install -q torch-sparse -f https://data.pyg.org/whl/torch-2.0.1+cu117.html\n",
    "pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
    "```\n",
    "\n",
    "4) finally, restart your kernel from the Noto interface: Kernel-> Restart Kernel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9-GQsoUdqGrw"
   },
   "source": [
    "If you are runing this notebook on Google Colab you can run the following cell to install the packages necessary for the exercise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-03-27T08:34:06.492004Z",
     "iopub.status.busy": "2024-03-27T08:34:06.491034Z",
     "iopub.status.idle": "2024-03-27T08:34:07.047212Z",
     "shell.execute_reply": "2024-03-27T08:34:07.043843Z",
     "shell.execute_reply.started": "2024-03-27T08:34:06.491934Z"
    },
    "id": "kuYeb8eKk7N8",
    "outputId": "68544b52-191b-4b24-cb1a-7c7f641c8b36"
   },
   "outputs": [],
   "source": [
    "# taken from MIT Copyright (c) 2023 PyG Team\n",
    "\n",
    "import os\n",
    "import torch\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "print(torch.__version__)\n",
    "\n",
    "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9HFMRgqZjT72"
   },
   "source": [
    "######**How can we represent a graph?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4PR16WTlboOx"
   },
   "source": [
    "A graph $\\mathcal{G}$ consist of a set nodes/verticies $\\mathcal{V}$ and the edges $\\mathcal{E}$ that connect them: $\\mathcal{G} = (\\mathcal{V}, \\mathcal{E})$.\n",
    "\n",
    "One of the ways of representing graphs is by having a set of nodes $\\mathcal{V}$, and a corresponding adjacency matrix $\\mathbf{A} \\in \\{ 0, 1 \\}^{|\\mathcal{V}| \\times |\\mathcal{V}|}$. In this matrix $a_{ij} = 1$ if there exists an edge that has $v_1$ node as a source and $v_2$ as a target, and $a_{ij} = 0$ otherwise.\n",
    "\n",
    "While storing information about edges in a matrix form (i.e., $\\mathbf{A}$) is a convenient mathematical notation, there is one issue: quite often big graphs are sparce, hence a big adjacency matrix would in reality contain only very little non-zero entries.\n",
    "\n",
    "Hence, there is an alternative way of writing the graph information, which is called coordinate format ([COO format](https://pytorch.org/docs/stable/sparse.html#sparse-coo-docs)). \"Instead of holding the adjacency information in a dense representation $\\mathbf{A} \\in \\{ 0, 1 \\}^{|\\mathcal{V}| \\times |\\mathcal{V}|}$, PyG represents graphs sparsely, which refers to only holding the coordinates/values for which entries in $\\mathbf{A}$ are non-zero.\"\n",
    "([reference](https://colab.research.google.com/drive/1h3-vJGRVloF5zStxL5I0rSy4ZUPNsjy8?usp=sharing#scrollTo=kVARD8kstxAY))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H5NgWaO9jcyG"
   },
   "source": [
    "######**How to load and to view the dataset?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NauKiTiujgae"
   },
   "source": [
    "PyG has a collection of the graph datasets available, which is accessible via this [`torch_geometric.datasets`](https://pytorch-geometric.readthedocs.io/en/latest/modules/datasets.html#torch_geometric.datasets) subpackage. If you want to upload your custom dataset with graphs, you can check [official documentation](https://pytorch-geometric.readthedocs.io/en/latest/tutorial/create_dataset.html) for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Itch7iAdkldR"
   },
   "source": [
    "Let's now see how PyG stores the information about the datasets, using the following datasets as examples:\n",
    "\n",
    "*   [Zachary’s karate club](https://www.jstor.org/stable/pdf/3629752.pdf?casa_token=TOIWobNuTZYAAAAA:eHXH2WW93OILyPaJhkHWBzP8nKanLeo1SSn-bCe2DTS9gF2JM1nnbEdQawrx3beKYnxlDCfu_vx0RjYKsMog3yV9kOztpMMVdBWeKXbgMg6Zg86oNyIf0g) dataset\n",
    "*   [PROTEINS](https://www.researchgate.net/profile/Cheng-Soon-Ong/publication/7782805_Protein_Function_Prediction_via_Graph_Kernels/links/09e41507e5184631f4000000/Protein-Function-Prediction-via-Graph-Kernels.pdf) dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "INCTMkUt8xFI"
   },
   "source": [
    "**KarateClub** dataset\n",
    "\n",
    "\"Zachary’s karate club network from the “An Information Flow Model for Conflict and Fission in Small Groups” paper, containing 34 nodes, connected by 156 (undirected and unweighted) edges. Every node is labeled by one of four classes obtained via modularity-based clustering, following the “Semi-supervised Classification with Graph Convolutional Networks” paper. Training is based on a single labeled example per class, i.e. a total number of 4 labeled nodes.\" [(reference)](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.datasets.KarateClub.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T08:34:07.053193Z",
     "iopub.status.busy": "2024-03-27T08:34:07.052428Z",
     "iopub.status.idle": "2024-03-27T08:34:07.070400Z",
     "shell.execute_reply": "2024-03-27T08:34:07.068711Z",
     "shell.execute_reply.started": "2024-03-27T08:34:07.053113Z"
    },
    "id": "_rxS-hgb96BK"
   },
   "outputs": [],
   "source": [
    "# adopted from MIT Copyright (c) 2023 PyG Team\n",
    "\n",
    "def diplay_dataset_info(dataset):\n",
    "    \"\"\"\n",
    "    Displays basic information about the dataset with graphs.\n",
    "\n",
    "    Args:\n",
    "        dataset: dataset from torch_geometric.datasets\n",
    "    Returns:\n",
    "        None: This function does not return a value.\n",
    "    \"\"\"\n",
    "    print(f'Information about {dataset} dataset:')\n",
    "    print(f'    Number of graphs: {len(dataset)}')\n",
    "    print(f'    Number of features: {dataset.num_features}')\n",
    "    print(f'    Number of classes: {dataset.num_classes}')\n",
    "    print()\n",
    "\n",
    "def display_graph_info(dataset, graph_index):\n",
    "    \"\"\"\n",
    "    Displays basic information about the graph with  with graphs.\n",
    "\n",
    "    Args:\n",
    "        dataset: dataset from torch_geometric.datasets\n",
    "    Returns:\n",
    "        None: This function does not return a value.\n",
    "    \"\"\"\n",
    "    graph = dataset[graph_index]\n",
    "    print(f'Information about graph #{graph_index} from {dataset} dataset:')\n",
    "    print(f'    Number of nodes: {graph.num_nodes}')\n",
    "    print(f'    Number of edges: {graph.num_edges}')\n",
    "    print(f'    Average node degree: {graph.num_edges / graph.num_nodes:.2f}')\n",
    "    print(f'    Has isolated nodes: {graph.has_isolated_nodes()}')\n",
    "    print(f'    Has self-loops: {graph.has_self_loops()}')\n",
    "    print(f'    Is undirected: {graph.is_undirected()}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-03-27T08:34:07.073255Z",
     "iopub.status.busy": "2024-03-27T08:34:07.072956Z",
     "iopub.status.idle": "2024-03-27T08:34:20.070286Z",
     "shell.execute_reply": "2024-03-27T08:34:20.068165Z",
     "shell.execute_reply.started": "2024-03-27T08:34:07.073221Z"
    },
    "id": "b7NTrtYq83H8",
    "outputId": "f41c015b-3dac-432f-fe9c-844f6068032e"
   },
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import KarateClub\n",
    "karate_dataset = KarateClub()\n",
    "\n",
    "#displaying information about the dataset\n",
    "diplay_dataset_info(karate_dataset)\n",
    "\n",
    "#displaying information about the graph with index 0\n",
    "display_graph_info(karate_dataset, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lsTdn1nHAgAd"
   },
   "source": [
    "**PROTEINS** dataset contains information for binary classification of proteins (enzymes and non-enzymes). \"Each graph represents exactly one protein. Nodes in our graph represent SSEs within the protein structure, i.e. helices, sheets and turns. Edges connect nodes if those are neighbors along the AA sequence or if they are neighbors in space within the protein structure. Every node is connected to its three nearest spatial neighbors.\" [(reference)](https://www.researchgate.net/profile/Cheng-Soon-Ong/publication/7782805_Protein_Function_Prediction_via_Graph_Kernels/links/09e41507e5184631f4000000/Protein-Function-Prediction-via-Graph-Kernels.pdf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-03-27T08:34:20.074191Z",
     "iopub.status.busy": "2024-03-27T08:34:20.073198Z",
     "iopub.status.idle": "2024-03-27T08:34:20.330964Z",
     "shell.execute_reply": "2024-03-27T08:34:20.328177Z",
     "shell.execute_reply.started": "2024-03-27T08:34:20.074121Z"
    },
    "id": "dBP81jdul2px",
    "outputId": "d1d80cdd-6d32-4185-b484-57aae315249d"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.datasets import TUDataset\n",
    "\n",
    "proteins_dataset = TUDataset(root='data/TUDataset', name='PROTEINS')\n",
    "\n",
    "diplay_dataset_info(proteins_dataset)\n",
    "display_graph_info(proteins_dataset, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gfc62M9Nn8Qn"
   },
   "source": [
    "Note the difference in **number of graphs** in the datasets. If we are performing nodes prediction, or community detection, it might be sufficient to only have one graph in the dataset. However, if we are performing classification on graphs, we need more than one graph for this task.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OTT5U0sy8bdK"
   },
   "source": [
    "###### **What is a graph in PyG?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kx7U4DyKp64G"
   },
   "source": [
    "\"Each graph in PyTorch Geometric is represented by a single [`Data`](https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html#torch_geometric.data.Data) object, which holds all the information to describe its graph representation.\"[(reference)](https://colab.research.google.com/drive/1h3-vJGRVloF5zStxL5I0rSy4ZUPNsjy8?usp=sharing#scrollTo=NgcpV4rjAWy-)\n",
    "Let's use `print(proteins_dataset[0])` to receive a short summary about the graph attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-03-27T08:34:20.337825Z",
     "iopub.status.busy": "2024-03-27T08:34:20.335768Z",
     "iopub.status.idle": "2024-03-27T08:34:20.347425Z",
     "shell.execute_reply": "2024-03-27T08:34:20.345659Z",
     "shell.execute_reply.started": "2024-03-27T08:34:20.337683Z"
    },
    "id": "miCX-uwRp_ts",
    "outputId": "765cadee-a786-4221-8a52-1b1934f081af"
   },
   "outputs": [],
   "source": [
    "print(proteins_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fumil5f69eMm"
   },
   "source": [
    "`Data object has a number of attributes, see [documentation](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data) for explanations:\n",
    "\n",
    "* `edge_index` – \"Graph connectivity in COO format with shape `[2, num_edges]`\"\n",
    "* `x` – \"Node feature matrix with shape `[num_nodes, num_node_features]`\"\n",
    "* `y` – \"Graph-level or node-level ground-truth labels with arbitrary shape.\" You can typically understand this from context. For example, in the PROTEINS dataset, there is only one label per graph, but there are 42 nodes, hence we conclude this is a graph label, and not a node label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qdPzfWwUb4we"
   },
   "source": [
    "\"Importantly, PyG does not distinguish between directed and undirected graphs, and treats undirected graphs as a special case of directed graphs in which reverse edges exist for every entry in `edge_index`.\" [(reference)](https://colab.research.google.com/drive/1h3-vJGRVloF5zStxL5I0rSy4ZUPNsjy8?usp=sharing#scrollTo=NgcpV4rjAWy-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SNDbl7hBCISS"
   },
   "source": [
    "######**How to prepare data for training?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i22S84dWB6pL"
   },
   "source": [
    "Later in this notebook you will be performing graph classification using GCN on the PROTEINS dataset. We have already loaded the dataset, now let's split it into the training and test sets, and into mini-batches.\n",
    "\n",
    "PyG offers its own [`DataLoader`](https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html#torch_geometric.data.DataLoader), which allows to optimize how the graphs are stored. For more details on DataLoader, see [this](https://colab.research.google.com/drive/1I8a0DfQ3fI7Njc62__mVXUlcAleUclnb#scrollTo=G-DwBYkquRUN) link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-03-27T08:34:20.349682Z",
     "iopub.status.busy": "2024-03-27T08:34:20.349219Z",
     "iopub.status.idle": "2024-03-27T08:34:20.512510Z",
     "shell.execute_reply": "2024-03-27T08:34:20.510158Z",
     "shell.execute_reply.started": "2024-03-27T08:34:20.349642Z"
    },
    "id": "6sYgIpE4CtOI",
    "outputId": "b670d3b4-cfa2-4215-c47a-9b9e8a1740ef"
   },
   "outputs": [],
   "source": [
    "# adopted from MIT Copyright (c) 2023 PyG Team\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "dataset = proteins_dataset.shuffle()\n",
    "\n",
    "train_dataset = dataset[:700]\n",
    "test_dataset = dataset[700:]\n",
    "\n",
    "print(f'Number of training graphs: {len(train_dataset)}')\n",
    "print(f'Number of test graphs: {len(test_dataset)}')\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tfB9Zb41QO91"
   },
   "source": [
    "##### **6.2 Message passing framework**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QeCmGtYjxq4W"
   },
   "source": [
    "######**Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2APIErTAxiX9"
   },
   "source": [
    "[**Message Passing Neural Network (MPNN)**](https://doi.org/10.48550/arXiv.1704.01212) (Gilmer et al. 2017) is a general framework for learning on graphs that standardizes different models independently proposed by several research groups. While different works use different notations and names, we will follow the notation used in Bishop's book.\n",
    "\n",
    "The message passing algorithm that characterizes this class of models is a two steps procedure which consists, for each node, in collecting a signal from its neighbours and use it to update its hidden state. The goal is to find a new representation of the nodes in the graph, such that each node's new representation considers not only its own features but also the relevant information from its neighbours. This process allows to encode the structural and feature-based context of each node within the graph, and this richer representation can then be used for different learning tasks, at the node, edge or graph level.\n",
    "\n",
    "At each iteration $l+1$ and for each node $n$, a message $\\boldsymbol z^{(l)}$ is computed as a function, called $\\mathrm{Aggregate}$, of the hidden state of its neighbouring nodes:\n",
    "\n",
    "$(1) \\qquad \\qquad \\boldsymbol z^{(l)} = \\mathrm{Aggregate}(\\{\\boldsymbol h_m^{(l)}: m \\in \\mathcal N(n)\\})$\n",
    "\n",
    "In general, as proposed in the original work, the inputs of $\\mathrm{Aggregate}$ can include the hidden state $\\boldsymbol h_n^{(l)}$ and the attributes of the connected edges $\\boldsymbol e_{nm}$.\n",
    "\n",
    "In the second step, the message is used to update the hidden state of $n$:\n",
    "\n",
    "$(2) \\qquad \\qquad \\boldsymbol h_n^{(l+1)} = \\mathrm{Update}(\\boldsymbol h_n^{(l)}, \\boldsymbol z^{(l)})$\n",
    "\n",
    "The choice of $\\mathrm{Aggregate}$ and $\\mathrm{Update}$ defines different types of layers fitting the Message Passing framework. Both functions need to be **differentiable** and can be parametrized. Additionally, $\\mathrm{Aggregate}$ should also be **permutation invariant** IE: invariant with respect to the order of neighbours.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zrH039csRKEg"
   },
   "source": [
    "Custom message passing layers can be easily implemented in Pytorch Geometric from the base MessagePassing class (see [documentation](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.MessagePassing.html)). The terminology used by PyG is slightly different than what we defined. In particular, it splits the $\\mathrm{Aggregate}$ function into two methods:\n",
    "\n",
    "\n",
    "*   `message`, which transforms the signal from a single node $m$\n",
    "*   `aggregate`, which combines the transformed signals from the neighbours into a single message\n",
    "\n",
    "For simplicity, instead of defining `aggregate` it is possible to use one of the standard aggregation methods - such as `mean` or `sum` - by passing it as the `aggr` input argument to the class `__init__` method.\n",
    "\n",
    "Another option, which might result in more efficient computations, is to implement the class method `message_and_aggregate`. If defined, this method will be called instead of `message` and `aggregate`.\n",
    "\n",
    "We will now create a simple example where the $\\mathrm{Aggregate}$ function will form the message by multiplying the neighbouring nodes' features by the identity matrix and aggregate them by taking the maximum value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T08:34:20.516414Z",
     "iopub.status.busy": "2024-03-27T08:34:20.515594Z",
     "iopub.status.idle": "2024-03-27T08:34:20.536380Z",
     "shell.execute_reply": "2024-03-27T08:34:20.534307Z",
     "shell.execute_reply.started": "2024-03-27T08:34:20.516345Z"
    },
    "id": "SLvOOynLRMyN"
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops\n",
    "\n",
    "# The standard approach is to create a class that inherits from MessagePassing\n",
    "class CustomLayer(MessagePassing):\n",
    "    # The input in_channels and out_channels are needed to define the dimensionality\n",
    "    # of the weight matrix. We also add an option to temporarily add self loops\n",
    "    # (IE: edges from each node to itself) in the forward pass\n",
    "    def __init__(self, in_channels, out_channels, add_self_loops=False):\n",
    "        # We want for this example in_channels and out_channels to be the same\n",
    "        assert in_channels == out_channels\n",
    "        # Initialize the base MessagePassing class with max aggregation. This\n",
    "        # will save us some code as we do not have to define the aggregate method\n",
    "        super(CustomLayer, self).__init__(aggr='max')\n",
    "        # Manually define the weight matrix as the identity matrix.\n",
    "        # Requires_grad is set to False to fix the weights.\n",
    "        self.weights = torch.nn.Parameter(torch.eye(in_channels, out_channels),\n",
    "                                          requires_grad=False)\n",
    "        # Wether to add self loops or not\n",
    "        self.add_self_loops = add_self_loops\n",
    "\n",
    "\n",
    "    def message(self, x_j):\n",
    "        # x_j denotes the features of source nodes j, which are being aggregated\n",
    "        # to target nodes i. Instead of multiplying the features by the identity\n",
    "        # matrix here, where this multiplication would be done for each connected\n",
    "        # node pair, we will do it with a single multiplication in the forward method\n",
    "        return x_j\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        # aggr_out is the result of aggregation (max in this case). We do not\n",
    "        # implement any $Update$ function in this example\n",
    "        return aggr_out\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # Optionally, add self-loops to the adjacency matrix.\n",
    "        if self.add_self_loops:\n",
    "          edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "\n",
    "        # Multiply node features by the identity matrix. While this is\n",
    "        # conceptually part of the message method, implementing it here is more\n",
    "        # efficient and would avoid redundant multiplications\n",
    "        x = torch.matmul(x, self.weights)\n",
    "\n",
    "        # Start propagating messages. Propagate will internally call message(),\n",
    "        # aggregate() and update()\n",
    "        return self.propagate(edge_index, size=(x.size(0), x.size(0)), x=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ZewvIeCx7VS"
   },
   "source": [
    "######**A simple example: node coloring**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rHLAYeoQRSwM"
   },
   "source": [
    "Let's imagine we have a graph where a node can be either purple - represented by a value of 0 - or yellow - represented by a value of 1. Our task is to use the custom layer just defined to color all nodes in yellow if there exists at least one yellow node. We will use two utility functions, to create the graph and visualize the output of model with an arbitrary number of CustomLayers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T08:34:20.541025Z",
     "iopub.status.busy": "2024-03-27T08:34:20.539732Z",
     "iopub.status.idle": "2024-03-27T08:34:22.392105Z",
     "shell.execute_reply": "2024-03-27T08:34:22.389482Z",
     "shell.execute_reply.started": "2024-03-27T08:34:20.540909Z"
    },
    "id": "-6pqxwjrUjb3"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "def build_grid_graph(size):\n",
    "    \"\"\"\n",
    "    Builds the edge index tensor for a 2D grid graph of a specified size.\n",
    "\n",
    "    Args:\n",
    "        size (int): The size of one dimension of the square grid.\n",
    "\n",
    "    Returns:\n",
    "        edge_index (torch.Tensor): A PyTorch tensor of shape (2, num_edges),\n",
    "              containing the indices of the source and target nodes of each edge\n",
    "              in the graph.\n",
    "\n",
    "    Note:\n",
    "    The grid graph is assumed to be undirected and square.\n",
    "    \"\"\"\n",
    "    edges = []\n",
    "    for i in range(size):\n",
    "        for j in range(size):\n",
    "            n = i * size + j  # Node index\n",
    "            if j < size - 1:\n",
    "                edges.append([n, n + 1])  # Right neighbour\n",
    "            if i < size - 1:\n",
    "                edges.append([n, n + size])  # Down neighbour\n",
    "    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "    # Add edges in both directions (undirected graph)\n",
    "    edge_index = torch.cat([edge_index, edge_index[[1, 0], :]], dim=1)\n",
    "    return edge_index\n",
    "\n",
    "\n",
    "def plot_graph_with_colored_nodes(model, data, title, size):\n",
    "    \"\"\"\n",
    "    Visualizes a 2D grid graph using the node features generated by a GNN model,\n",
    "    with nodes colored according to their feature values.\n",
    "\n",
    "    Args:\n",
    "        model: A PyTorch Geometric model that is applied to the data.\n",
    "        data: A PyTorch Geometric Data object containing the graph to visualize.\n",
    "              It must include node features x and the edge index.\n",
    "        title (str): The title for the plot.\n",
    "        size (int): The size of one dimension of the square 2D grid graph.\n",
    "\n",
    "    Returns:\n",
    "        None: This function does not return a value.\n",
    "    \"\"\"\n",
    "    if model is not None:\n",
    "      with torch.no_grad():\n",
    "          out_features = model(data.x, data.edge_index)\n",
    "    else:\n",
    "          out_features = data.x\n",
    "\n",
    "    # Convert to 1D for visualization\n",
    "    node_colors = out_features.numpy().mean(axis=1)\n",
    "\n",
    "    # Create networkx graph\n",
    "    G = nx.grid_2d_graph(size, size)\n",
    "    pos = dict((n, n) for n in G.nodes())\n",
    "    labels = dict(zip(G.nodes(), out_features.flatten().tolist()))\n",
    "\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    nx.draw(G, pos, labels=labels, node_size=600, cmap=plt.cm.viridis,\n",
    "            node_color=node_colors, with_labels=True, font_weight='bold',\n",
    "            vmin=0, vmax=1)\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vJEqJ6idRY9R"
   },
   "source": [
    "We create a 5x5 grid graph for our example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "execution": {
     "iopub.execute_input": "2024-03-27T08:34:22.400144Z",
     "iopub.status.busy": "2024-03-27T08:34:22.399065Z",
     "iopub.status.idle": "2024-03-27T08:34:22.874407Z",
     "shell.execute_reply": "2024-03-27T08:34:22.873049Z",
     "shell.execute_reply.started": "2024-03-27T08:34:22.400085Z"
    },
    "id": "SOiDHUdhCMkz",
    "outputId": "1b357625-0936-4e63-f387-9f8eec5d45af"
   },
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "#the height/width of the grid\n",
    "size = 5\n",
    "num_nodes = size * size\n",
    "\n",
    "#we use utility function above to build the adjacency matrix in the COO format\n",
    "edge_index = build_grid_graph(size)\n",
    "\n",
    "# here the data variable will contain information about our graph\n",
    "# (which is a Data structure)\n",
    "data = Data(edge_index=edge_index)\n",
    "\n",
    "# x contains a single binary feature with value 1 for the central node\n",
    "data.x = torch.zeros((num_nodes, 1))\n",
    "\n",
    "#manually labelling the central node\n",
    "data.x[12, 0] = 1\n",
    "\n",
    "title = 'Original graph'\n",
    "plot_graph_with_colored_nodes(None, data, title, size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uzdiC2PIRSjK"
   },
   "source": [
    "We can then create a CustomModel class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T08:34:22.876095Z",
     "iopub.status.busy": "2024-03-27T08:34:22.875788Z",
     "iopub.status.idle": "2024-03-27T08:34:22.886335Z",
     "shell.execute_reply": "2024-03-27T08:34:22.884996Z",
     "shell.execute_reply.started": "2024-03-27T08:34:22.876069Z"
    },
    "id": "RsYsNxYsbLmP"
   },
   "outputs": [],
   "source": [
    "class CustomModel(torch.nn.Module):\n",
    "    def __init__(self, input_dim, num_layers,\n",
    "                 add_self_loops=False):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        self.layers.append(CustomLayer(input_dim, input_dim, add_self_loops))\n",
    "\n",
    "        for _ in range(num_layers - 1):\n",
    "            self.layers.append(CustomLayer(input_dim, input_dim, add_self_loops))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        if self.num_layers == 0:\n",
    "            return x\n",
    "        for layer in self.layers[:-1]:\n",
    "            x = layer(x, edge_index)\n",
    "        x = self.layers[-1](x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8BPUTPjhR0rf"
   },
   "source": [
    "And define the dimensionality of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T08:34:22.887724Z",
     "iopub.status.busy": "2024-03-27T08:34:22.887449Z",
     "iopub.status.idle": "2024-03-27T08:34:22.926467Z",
     "shell.execute_reply": "2024-03-27T08:34:22.924130Z",
     "shell.execute_reply.started": "2024-03-27T08:34:22.887683Z"
    },
    "id": "soza3ovvR1d2"
   },
   "outputs": [],
   "source": [
    "# we consider an input dimension of one as each node is represented by one feature that is the color\n",
    "input_dim = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LpgQOw8a_GGm"
   },
   "source": [
    "We can now test the effect of different number of layers.\n",
    "\n",
    "Do you think we can color the whole graph? If yes, how many layers do we need?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2024-03-27T08:34:22.930662Z",
     "iopub.status.busy": "2024-03-27T08:34:22.929028Z",
     "iopub.status.idle": "2024-03-27T08:34:24.008100Z",
     "shell.execute_reply": "2024-03-27T08:34:24.006873Z",
     "shell.execute_reply.started": "2024-03-27T08:34:22.930590Z"
    },
    "id": "EsZuSsFf_NrN",
    "outputId": "5c461bdd-d3f2-4774-8ca6-f456d690c0d0"
   },
   "outputs": [],
   "source": [
    "for num_layers in range(5):\n",
    "    model = CustomModel(input_dim, num_layers)\n",
    "    if num_layers == 0:\n",
    "      title = 'Original graph'\n",
    "    else:\n",
    "      title = f'Graph after {num_layers} Layers'\n",
    "    plot_graph_with_colored_nodes(model, data, title, size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wGoNmKRbDKaH"
   },
   "source": [
    "Notice what is happening: at each iteration, the nodes that are adjacent to a yellow node are being colored as we expected (the maximum value of the neighbours is 1). However, colored nodes are losing the information of their previous hidden state, and since all neighbours have a hidden state of 0 their new state is 0. Sometimes, like in this case, we need to combine the received message with the previous hidden state of the node. A common way to do this is to add a virtual edge between each node and itself, also called a \"self loop\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2024-03-27T08:34:24.009563Z",
     "iopub.status.busy": "2024-03-27T08:34:24.009295Z",
     "iopub.status.idle": "2024-03-27T08:34:25.090133Z",
     "shell.execute_reply": "2024-03-27T08:34:25.088864Z",
     "shell.execute_reply.started": "2024-03-27T08:34:24.009539Z"
    },
    "id": "nJ70u5nnDfmY",
    "outputId": "027f0e5c-4132-47c2-892b-ed08fa9fb1a6"
   },
   "outputs": [],
   "source": [
    "for num_layers in range(5):\n",
    "    model = CustomModel(input_dim, num_layers,\n",
    "                        add_self_loops=True)\n",
    "    if num_layers == 0:\n",
    "      title = 'Original graph'\n",
    "    else:\n",
    "      title = f'Graph after {num_layers} Layers and self loops'\n",
    "    plot_graph_with_colored_nodes(model, data, title, size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HSYQt8AhCj1u"
   },
   "source": [
    "This simple example shows how a node in a graph can incorporate information from its surroundings using several iterations of message passing. The propagation of information is linked to the concept of \"receptive field.\" This term describes the maximum distance for which a node is influenced by other nodes in the graph, a characteristic determined by the number of layers, also called depth. Through adjusting the model's depth, we can extend a node's ability to access and integrate distant information in the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NKVO8P0oxM0N"
   },
   "source": [
    "######**A more expressive message passing layer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CYCGqCWcIDPi"
   },
   "source": [
    "In most real-world applications, we will use layers that have more expressive $\\mathrm{Aggregate}$ and $\\mathrm{Update}$ functions. One of the first, and most known examples is the building block of the Graph Convolutional Network (GCN) proposed by (Kipf and Welling, 2016), which uses the following $\\mathrm{Aggregate}$ function:\n",
    "\n",
    "$\\mathrm{Aggregate}(\\{\\boldsymbol h_m^{(l)}: m \\in \\mathcal N(n)\\}) = \\sum\\limits_{m \\in \\mathcal N(n)}\\frac{\\boldsymbol h_m^{(l)}}{\\sqrt{|\\mathcal N(n)||\\mathcal N(m)|}}$\n",
    "\n",
    "The $\\mathrm{Update}$ function is then:\n",
    "\n",
    "$\\mathrm{Update}(\\boldsymbol h_n^{(l)}, \\boldsymbol z^{(l)}) = \\sigma^{(l)} \\left( \\boldsymbol W_\\theta^{(l)} \\boldsymbol z^{(l)} \\right)$\n",
    "\n",
    "Where $\\boldsymbol W_\\theta^{(l)}$ is a matrix of learnable parameters and $\\sigma$ is an activation function, commonly $\\mathrm{ReLU}$.\n",
    "\n",
    "Such a layer is implemented in Pytorch Geometric as GCNConv [(reference)](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.GCNConv.html), with the main remark that the $\\mathrm{Update}$ function does not include the non-linear activation $\\sigma$, which is instead commonly added between layers in the forward method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ikNRhcKOzV9i"
   },
   "source": [
    "######**Creating the model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pmECaoyWQTj-"
   },
   "source": [
    "##### **6.3 Implementation of GCN on the PROTEINS dataset**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1rgJtt3NkTTt"
   },
   "source": [
    "GCN model is based on graph convolutions, which can be built by stacking multiple\n",
    "convolutional layers, where \"each layer followed by a point-wise non-linearity\" [(reference: paper that introduced GCN)](https://arxiv.org/pdf/1609.02907.pdf)\n",
    "\n",
    "We now implement a GCN model and train it on the PROTEINS dataset for a binary classification task, to predict whether the given protein (graph) is an enzyme.\n",
    "\n",
    "So far, we have worked on a node level and there has been one output for each node. With the PROTEINS dataset we are performing a graph-level binary classification - whether the considered protein is an enzyme or not. For this reason, we need to somehow combine the final embeddings of the nodes into a vector the size of which does not depend on the number of nodes in the graph. This is done by introducing a third function in the message-passing framework, often called $\\mathrm{Readout}$, such that:\n",
    "\n",
    "$(3) \\qquad \\qquad \\boldsymbol y = \\mathrm{Readout}\\left(\\left\\{ \\boldsymbol h_n^{(L)} \\; : \\; n \\in \\mathcal V \\right\\}\\right) $\n",
    "\n",
    "$\\mathrm{Readout}$ must be **differentiable** and **permutation invariant**, as the order in which the node embeddings are passed to the function should not change its output.\n",
    "\n",
    "In this final example, we will use a global mean pooling function [(reference)](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.global_mean_pool.html) as a readout function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mWxmLd6QeLtd"
   },
   "source": [
    "**TODO**: implement GCN model and train it on the PROTEINS dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "execution": {
     "iopub.execute_input": "2024-03-27T08:34:25.091799Z",
     "iopub.status.busy": "2024-03-27T08:34:25.091466Z",
     "iopub.status.idle": "2024-03-27T08:34:25.207398Z",
     "shell.execute_reply": "2024-03-27T08:34:25.206231Z",
     "shell.execute_reply.started": "2024-03-27T08:34:25.091770Z"
    },
    "id": "_E9Wu4U5zWGx",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8af041f4cae34ae869bd21e0dc59f558",
     "grade": false,
     "grade_id": "cell-d3d82e350ec057b3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "4df66b28-d466-42ad-bfb1-07dab0b1c140",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# adopted from MIT Copyright (c) 2023 PyG Team\n",
    "\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels_1, hidden_channels_2):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(42)\n",
    "        # define the conv1, conv2, conv3, and a linear layers for the GCN\n",
    "        # conv1 layer is a Graph Convolutional Layer, with in_channels as num_node_features and out_channels as hidden_channels_1\n",
    "        # conv2 layer is a Graph Convolutional Layer, with in_channels as hidden_channels_1 and out_channels as hidden_channels_2\n",
    "        # conv3 layer is a Graph Convolutional Layer, with in_channels as hidden_channels_2 and out_channels as hidden_channels_1\n",
    "        # linear layer is a Linear layer with in_channels as hidden_channels_1 and out_channels as num_classes\n",
    "\n",
    "        # write 4 lines of code\n",
    "        # self.conv1 = ...\n",
    "        # self.conv2 = ...\n",
    "        # self.conv3 = ...\n",
    "        # self.lin = ...\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # perform a forward pass, using ReLU activation function after conv1 and conv2\n",
    "\n",
    "        # Step 1: propagate signal in convolutional layers\n",
    "        # Step 2: apply the global_mean_pool as a readout function\n",
    "        # Step 3: add the dropout with p=0.5\n",
    "        # Step 4: propagate signal in a linear layer\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "        return x\n",
    "\n",
    "model = GCN(hidden_channels_1 = 32, hidden_channels_2 = 64)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S0tqQYjeafRx"
   },
   "source": [
    "######**Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OeNW414GyaDS"
   },
   "source": [
    "**TODO**: train the GCN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "deletable": false,
    "execution": {
     "iopub.execute_input": "2024-03-27T08:34:25.208781Z",
     "iopub.status.busy": "2024-03-27T08:34:25.208506Z",
     "iopub.status.idle": "2024-03-27T08:34:47.944548Z",
     "shell.execute_reply": "2024-03-27T08:34:47.943246Z",
     "shell.execute_reply.started": "2024-03-27T08:34:25.208757Z"
    },
    "id": "dxR4yDHzaHJY",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0973f58a60549de322bd4a59da3dc2c8",
     "grade": false,
     "grade_id": "cell-6501102a1299a209",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "30be8726-4dd4-4d22-9c99-b109409198c6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Implement code for training and evaluating the GCN model above.\n",
    "# You can re-use code from the previous labs\n",
    "# Define the model, optimizer, and the criterion that could be used.\n",
    "# Train the model for at least 50 epochs.\n",
    "# For reference: state of the art performance on this dataset is 84.91 (accuracy).\n",
    "# see https://paperswithcode.com/sota/graph-classification-on-proteins\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "EE559_audio",
   "language": "python",
   "name": "ee559_audio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
